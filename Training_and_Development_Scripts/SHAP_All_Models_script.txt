import joblib  
import pandas as pd  
import numpy as np  
import shap  
import matplotlib.pyplot as plt  
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier

# Load the preprocessor  
preprocessor = joblib.load('saved_models/preprocessor_v2.joblib')  

# Define the target column  
target_column = 'Churn'  

# Load Data  
train_data = pd.read_csv(r"C:\Users\charles\Downloads\Bablola Charles Olugbenga\archive (22)\churn-bigml-80.csv")  
test_data = pd.read_csv(r"C:\Users\charles\Downloads\Bablola Charles Olugbenga\archive (22)\churn-bigml-20.csv")   

# Prepare the test data  
X_test = test_data.drop(columns=[target_column])  
y_test = test_data[target_column]  

# Transform the test data  
X_test_transformed = preprocessor.transform(X_test)  

# Ensure the transformed data is a dense array  
if hasattr(X_test_transformed, "todense"):  
    X_test_transformed = X_test_transformed.todense()  

# Ensure there are no NaN values  
X_test_transformed = np.nan_to_num(X_test_transformed)  

# Function to process SHAP values and generate explanations  
def process_shap_values(model_name):  
    # Load the model  
    model = joblib.load(f'saved_models/{model_name}.joblib')  
    
    # Special handling for the stacking model (hybrid model)
    if model_name == 'stacking_model_v2':
        try:
            # Load the individual models' SHAP values
            shap_values_rf = np.load('saved_models/shap_values_random_forest_model_v2.npy')
            shap_values_gb = np.load('saved_models/shap_values_gradient_boosting_model_v2.npy')
            shap_values_dt = np.load('saved_models/shap_values_decision_tree_model_v2.npy')

            # Average the SHAP values
            averaged_shap_values = (shap_values_rf + shap_values_gb + shap_values_dt) / 3

            # Calculate feature importance
            shap_importance = np.abs(averaged_shap_values).mean(axis=0)
            feature_names = preprocessor.get_feature_names_out()

            # Create DataFrame for feature importance
            shap_importance_df = pd.DataFrame({
                'Feature': feature_names,
                'Importance': shap_importance
            }).sort_values(by='Importance', ascending=False)

            # Save SHAP explanation text for the stacking model
            with open(f'saved_models/shap_explanation_{model_name}.txt', 'w') as f:
                f.write(shap_importance_df.to_string(index=False))

            # Plot the averaged SHAP values
            plt.figure(figsize=(10, 6))
            shap.summary_plot(averaged_shap_values, X_test_transformed, feature_names=feature_names, show=False)
            plt.title('SHAP Summary Plot (Stacking Model - Averaged SHAP)')
            plt.tight_layout()
            plt.savefig(f'saved_models/shap_summary_{model_name}_averaged.png')
            plt.close()

            # Plot top 7 feature importance bar chart
            top_7_features = shap_importance_df.head(7)
            plt.figure(figsize=(8, 5))
            plt.barh(top_7_features['Feature'], top_7_features['Importance'], color=plt.cm.viridis(np.linspace(0, 1, 7)))
            plt.xlabel('Importance')
            plt.title(f'Top 7 Features - SHAP Importance ({model_name})')
            plt.gca().invert_yaxis()  # Invert y-axis to have the highest importance on top
            plt.tight_layout()
            plt.savefig(f'saved_models/shap_top7_features_{model_name}.png')
            plt.close()

            print(f"SHAP summary plot for {model_name} (averaged) saved successfully!")
            print(f"Top 7 feature importance chart for {model_name} saved successfully!")
            return  # Exit the function after handling the stacking model
        except FileNotFoundError as e:
            print(f"Error: {e}. Please ensure SHAP values for base models are saved first.")
            return

    # Check if the model is a pipeline or a standalone classifier  
    if hasattr(model, 'named_steps'):  
        classifier = model.named_steps['classifier']  
    else:  
        classifier = model  # It's a standalone classifier  

    # Choose appropriate SHAP explainer based on the model type  
    if isinstance(classifier, (RandomForestClassifier, DecisionTreeClassifier)):
        explainer = shap.TreeExplainer(classifier)
    else:
        explainer = shap.Explainer(classifier)  # Use the appropriate explainer for non-tree models  
    
    # Generate SHAP values  
    shap_values = explainer(X_test_transformed)  

    # Check if shap_values is a list (for multi-class models)
    if isinstance(shap_values, list):  
        shap_values = shap_values[1]  # Select the SHAP values for the positive class  

    # If shap_values have multiple dimensions (e.g., in case of classification)
    if shap_values.values.ndim == 3:
        shap_values = shap_values[:, :, 1]  # Get SHAP values for the positive class

    shap_importance = np.abs(shap_values.values).mean(axis=0)  
    feature_names = preprocessor.get_feature_names_out()  

    # Create DataFrame for feature importance  
    shap_importance_df = pd.DataFrame({  
        'Feature': feature_names,  
        'Importance': shap_importance  
    }).sort_values(by='Importance', ascending=False)  

    # Save SHAP explanation text  
    with open(f'saved_models/shap_explanation_{model_name}.txt', 'w') as f:  
        f.write(shap_importance_df.to_string(index=False))  

    # Plot SHAP summary  
    plt.figure(figsize=(10, 6))  
    shap.summary_plot(shap_values, X_test_transformed, feature_names=feature_names, show=False)  
    plt.title(f'SHAP Summary Plot ({model_name})')  
    plt.tight_layout()  
    plt.savefig(f'saved_models/shap_summary_{model_name}.png')  
    plt.close()  
    print(f"SHAP summary plot for {model_name} saved successfully!")  

    # Plot top 7 feature importance bar chart
    top_7_features = shap_importance_df.head(7)
    plt.figure(figsize=(8, 5))
    plt.barh(top_7_features['Feature'], top_7_features['Importance'], color=plt.cm.viridis(np.linspace(0, 1, 7)))
    plt.xlabel('Importance')
    plt.title(f'Top 7 Features - SHAP Importance ({model_name})')
    plt.gca().invert_yaxis()  # Invert y-axis to have the highest importance on top
    plt.tight_layout()
    plt.savefig(f'saved_models/shap_top7_features_{model_name}.png')
    plt.close()

    # Save the SHAP values for potential later use in stacking model
    np.save(f'saved_models/shap_values_{model_name}.npy', shap_values.values)
    print(f"Top 7 feature importance chart for {model_name} saved successfully!")

# List of model names to process  
models = ['decision_tree_model_v2', 'gradient_boosting_model_v2', 'random_forest_model_v2', 'stacking_model_v2']  

for name in models:  
    try:  
        process_shap_values(name)  
    except Exception as e:  
        print(f"Error during SHAP value calculation for {name}: {e}")

